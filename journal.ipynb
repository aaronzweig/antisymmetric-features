{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "178732ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78ddab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Block, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class OddProjBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(OddProjBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim + input_dim, output_dim, bias = False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.cat([F.relu(self.fc1(x)) - F.relu(self.fc1(-x)), x], dim = 1)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class Symmetric(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, symmetric_dim, output_dim):\n",
    "        super(Symmetric, self).__init__()\n",
    "        \n",
    "        self.phi = Block(input_dim, hidden_dim, symmetric_dim)\n",
    "        self.rho = Block(symmetric_dim, hidden_dim, output_dim)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):        \n",
    "        batch_size, input_set_dim, input_dim = x.shape\n",
    "        \n",
    "        x = x.view(-1, input_dim)\n",
    "        z = self.phi(x)\n",
    "        z = z.view(batch_size, input_set_dim, -1)\n",
    "        z = torch.mean(z, 1)\n",
    "        return self.rho(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dd5c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlaterDeterminant(nn.Module):\n",
    "    def __init__(self, n, input_dim, hidden_dim):\n",
    "        super(SlaterDeterminant, self).__init__()\n",
    "        self.orbitals = Block(input_dim, hidden_dim, n)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.n = n\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        sd = self.orbitals(x)\n",
    "        sd = sd.view(-1, n, n)\n",
    "        return torch.det(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b87a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiSlaterDeterminant(nn.Module):\n",
    "    def __init__(self, n, input_dim, hidden_dim, anti_dim):\n",
    "        super(MultiSlaterDeterminant, self).__init__()\n",
    "        self.orbitals = nn.ModuleList([Block(input_dim, hidden_dim, n) for _ in range(anti_dim)])\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.n = n\n",
    "        \n",
    "    def forward(self,x):        \n",
    "        #x = x.view(-1, self.input_dim)\n",
    "        #sds = [f(x).view(-1, self.n, self.n) for f in self.orbitals]\n",
    "        sds = [f(x) for f in self.orbitals]\n",
    "        sds = torch.stack(sds,1)\n",
    "        sds = torch.det(sds)\n",
    "        return torch.sum(sds, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45ec62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AntiNet(nn.Module):\n",
    "    def __init__(self, n, input_dim, hidden_dim, anti_dim):\n",
    "        super(AntiNet, self).__init__()\n",
    "        self.orbitals = nn.ModuleList([Block(input_dim, hidden_dim, n) for _ in range(anti_dim)])\n",
    "        self.g = OddProjBlock(anti_dim, hidden_dim, 1)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.n = n\n",
    "        \n",
    "    def forward(self,x):\n",
    "        sds = [f(x) for f in self.orbitals]\n",
    "        sds = torch.stack(sds,1)\n",
    "        sds = torch.det(sds)\n",
    "        return torch.flatten(self.g(sds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "190819a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAntiNet(nn.Module):\n",
    "    def __init__(self, n, input_dim, hidden_dim, anti_dim):\n",
    "        super(DeepAntiNet, self).__init__()\n",
    "        self.orbitals = nn.ModuleList([Block(input_dim, hidden_dim, n) for _ in range(anti_dim)])\n",
    "        self.g1 = OddProjBlock(anti_dim, hidden_dim, hidden_dim)\n",
    "        self.g2 = OddProjBlock(hidden_dim, hidden_dim, 1)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.n = n\n",
    "        \n",
    "    def forward(self,x):\n",
    "        sds = [f(x) for f in self.orbitals]\n",
    "        sds = torch.stack(sds,1)\n",
    "        sds = torch.det(sds)\n",
    "        sds = self.g1(sds)\n",
    "        return torch.flatten(self.g2(sds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "607a0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBackflow(nn.Module):\n",
    "    def __init__(self, n, input_dim, hidden_dim, anti_dim):\n",
    "        super(MultiBackflow, self).__init__()\n",
    "        self.sym = Symmetric(input_dim, hidden_dim, hidden_dim, hidden_dim)\n",
    "        self.push = Block(input_dim + hidden_dim, hidden_dim, input_dim)\n",
    "        self.orbitals = nn.ModuleList([Block(input_dim, hidden_dim, n) for _ in range(anti_dim)])\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.n = n\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_dim, set_dim, input_dim = x.shape\n",
    "        sym_feature = self.sym(x).unsqueeze(1).repeat(1, set_dim, 1)\n",
    "        z = torch.cat([x, sym_feature], 2)\n",
    "        z = self.push(z)\n",
    "        \n",
    "        sds = [f(z) for f in self.orbitals]\n",
    "        sds = torch.stack(sds,1)\n",
    "        sds = torch.det(sds)\n",
    "        return torch.sum(sds, dim = 1)\n",
    "    \n",
    "class DeepMultiBackflow(nn.Module):\n",
    "    def __init__(self, n, input_dim, hidden_dim, anti_dim):\n",
    "        super(DeepMultiBackflow, self).__init__()\n",
    "        self.sym = Symmetric(input_dim, hidden_dim, hidden_dim, hidden_dim)\n",
    "        self.push = Block(input_dim + hidden_dim, hidden_dim, input_dim)\n",
    "        self.orbitals = nn.ModuleList([Block(input_dim, hidden_dim, n) for _ in range(anti_dim)])\n",
    "        self.g1 = OddProjBlock(anti_dim, hidden_dim, hidden_dim)\n",
    "        self.g2 = OddProjBlock(hidden_dim, hidden_dim, 1)        \n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.n = n\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_dim, set_dim, input_dim = x.shape\n",
    "        sym_feature = self.sym(x).unsqueeze(1).repeat(1, set_dim, 1)\n",
    "        z = torch.cat([x, sym_feature], 2)\n",
    "        z = self.push(z)\n",
    "        \n",
    "        sds = [f(z) for f in self.orbitals]\n",
    "        sds = torch.stack(sds,1)\n",
    "        sds = torch.det(sds)\n",
    "        sds = self.g1(sds)\n",
    "        return torch.flatten(self.g2(sds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06d157b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0010e-05,  1.9118e-06], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([-1.0013e-05], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([1.9118e-06], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Validate batching\n",
    "\n",
    "n = 5\n",
    "d = 3\n",
    "hidden_dim = 20\n",
    "\n",
    "x = 10 * torch.normal(mean = 0, std = 1, size = (2, n, d))\n",
    "\n",
    "x0 = x[:1]\n",
    "x1 = x[1:]\n",
    "\n",
    "SD = DeepMultiBackflow(n, d, hidden_dim, 4)\n",
    "#SD = AntiNet(n, d, hidden_dim, 4)\n",
    "print(SD(x))\n",
    "print(SD(x0))\n",
    "print(SD(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a4b391a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.8524e-06], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([6.8524e-06], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Validate antisymmetry\n",
    "\n",
    "\n",
    "\n",
    "x = 10 * torch.normal(mean = 0, std = 1, size = (n, d))\n",
    "P = torch.eye(n)\n",
    "P[0,0] = P[1,1] = 0\n",
    "P[0,1] = P[1,0] = 1\n",
    "x_ = torch.mm(P, x)\n",
    "x = torch.unsqueeze(x, 0)\n",
    "x_ = torch.unsqueeze(x_, 0)\n",
    "\n",
    "SD = DeepMultiBackflow(n, d, hidden_dim, 3)\n",
    "y = SD(x)\n",
    "y_ = SD(x_)\n",
    "\n",
    "# ANN = AntiNet(n, d, hidden_dim, 3)\n",
    "# y = ANN(x)\n",
    "# y_ = ANN(x_)\n",
    "print(y)\n",
    "print(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f769974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, iterations, lr=0.005):\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    losses = []\n",
    "    for i in range(iterations):\n",
    "        outputs = model(x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "                \n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f81b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "d = 3\n",
    "hidden_dim = 20\n",
    "anti_dim = 5\n",
    "\n",
    "iterations = 20000\n",
    "samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c535103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = MultiSlaterDeterminant(n, d, hidden_dim, 200)\n",
    "train_x = 3 * torch.normal(mean = 0, std = 1, size = (samples, n, d))\n",
    "train_y = teacher(train_x).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "138075d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for _ in range(1):\n",
    "#     student = MultiSlaterDeterminant(n, d, hidden_dim, anti_dim)\n",
    "#     losses = train(student, train_x, train_y, iterations, lr = 0.0025)\n",
    "#     print(losses[::50])\n",
    "#     print(min(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8787676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for _ in range(1):\n",
    "#     student = AntiNet(n, d, hidden_dim, anti_dim)\n",
    "#     losses = train(student, train_x, train_y, iterations, lr = 0.0025)\n",
    "#     print(losses[::50])\n",
    "#     print(min(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3387989e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74.98603820800781, 12.448062896728516, 6.464196681976318, 4.879818916320801, 4.030492782592773, 3.530247211456299, 3.208014488220215, 2.978376865386963, 2.790480613708496, 2.6464672088623047, 2.5403292179107666, 2.4579055309295654, 2.3777809143066406, 2.302720308303833, 2.2359743118286133, 2.1958868503570557, 2.140211343765259, 2.102665901184082, 2.096693754196167, 2.0359768867492676, 2.0037131309509277, 1.9792101383209229, 1.9611250162124634, 1.9563833475112915, 1.8965578079223633, 1.8754156827926636, 1.8572744131088257, 1.8880958557128906, 1.8251302242279053, 1.814673662185669, 1.8229738473892212, 1.7819308042526245, 1.8033159971237183, 1.819546103477478, 1.735672116279602, 1.7281690835952759, 1.7095849514007568, 1.6916066408157349, 1.6836519241333008, 1.6800060272216797, 1.6810171604156494, 1.66530179977417, 1.6315369606018066, 1.6138352155685425, 1.6022917032241821, 1.6097099781036377, 1.5965417623519897, 1.5813536643981934, 1.544289469718933, 1.5281130075454712, 1.5643322467803955, 1.5787371397018433, 1.5992095470428467, 1.4690062999725342, 1.478680968284607, 1.4811705350875854, 1.4374253749847412, 1.427931547164917, 1.472215175628662, 1.454093098640442, 1.4467843770980835, 1.3947523832321167, 1.4233273267745972, 1.4054040908813477, 1.4103564023971558, 1.3802822828292847, 1.3847302198410034, 1.383860468864441, 1.3543660640716553, 1.3496946096420288, 1.3420785665512085, 1.3394752740859985, 1.3386622667312622, 1.3419371843338013, 1.3242664337158203, 1.3321559429168701, 1.3394206762313843, 1.3436723947525024, 1.3552652597427368, 1.3074774742126465, 1.3702147006988525, 1.299061894416809, 1.307733416557312, 1.3204591274261475, 1.3363120555877686, 1.314615249633789, 1.3177629709243774, 1.2836506366729736, 1.3548057079315186, 1.344069480895996, 1.2841248512268066, 1.302093505859375, 1.3059972524642944, 1.2956269979476929, 1.285818338394165, 1.298311471939087, 1.2593761682510376, 1.2546635866165161, 1.24531888961792, 1.2516584396362305, 1.24032723903656, 1.2450062036514282, 1.2339930534362793, 1.2509101629257202, 1.2296669483184814, 1.34050452709198, 1.2212581634521484, 1.2510087490081787, 1.223266363143921, 1.2202074527740479, 1.2167179584503174, 1.243281602859497, 1.2224582433700562, 1.2688140869140625, 1.2340630292892456, 1.1989188194274902, 1.2238906621932983, 1.2235572338104248, 1.1930326223373413, 1.2379374504089355, 1.2239030599594116, 1.3830708265304565, 1.2667460441589355, 1.258670449256897, 1.2252787351608276, 1.2009906768798828, 1.2316515445709229, 1.2231080532073975, 1.2089943885803223, 1.2220784425735474, 1.2037698030471802, 1.1911699771881104, 1.1860783100128174, 1.1824275255203247, 1.1949388980865479, 1.1784300804138184, 1.1996870040893555, 1.1699756383895874, 1.2116209268569946, 1.160109043121338, 1.1557313203811646, 1.165317177772522, 1.2048555612564087, 1.1504729986190796, 1.1489042043685913, 1.1644775867462158, 1.187438726425171, 1.1722229719161987, 1.1752039194107056, 1.1419445276260376, 1.1520863771438599, 1.191022515296936, 1.2139328718185425, 1.2228662967681885, 1.1481951475143433, 1.158629298210144, 1.1440224647521973, 1.177985668182373, 1.19247305393219, 1.1549582481384277, 1.1415510177612305, 1.1690782308578491, 1.200760006904602, 1.144540548324585, 1.2510393857955933, 1.115327000617981, 1.1216868162155151, 1.1472127437591553, 1.1482676267623901, 1.178067684173584, 1.286104440689087, 1.1196340322494507, 1.2685269117355347, 1.1299521923065186, 1.1196116209030151, 1.2097424268722534, 1.1150273084640503, 1.1170130968093872, 1.1220862865447998, 1.1158071756362915, 1.13286554813385, 1.1043219566345215, 1.1190497875213623, 1.1032400131225586, 1.0971498489379883, 1.1171663999557495, 1.1335369348526, 1.1276837587356567, 1.1081277132034302, 1.1033498048782349, 1.0921525955200195, 1.1294885873794556, 1.0935184955596924, 1.140670895576477, 1.1296628713607788, 1.110795259475708, 1.2833150625228882, 1.091090440750122, 1.093361735343933, 1.17313814163208, 1.1826215982437134, 1.0904392004013062, 1.0840808153152466, 1.1104787588119507, 1.1009955406188965, 1.0815695524215698, 1.1090224981307983, 1.1199052333831787, 1.1028186082839966, 1.0848536491394043, 1.078549861907959, 1.0995588302612305, 1.163535475730896, 1.1108295917510986, 1.0978385210037231, 1.0917168855667114, 1.2260618209838867, 1.08903169631958, 1.0805742740631104, 1.0717694759368896, 1.1542142629623413, 1.1119459867477417, 1.1168371438980103, 1.1267038583755493, 1.0687708854675293, 1.070765733718872, 1.1110098361968994, 1.0669342279434204, 1.148016095161438, 1.116909384727478, 1.1018378734588623, 1.0807334184646606, 1.0769375562667847, 1.0927083492279053, 1.189481496810913, 1.142711877822876, 1.0871220827102661, 1.1214618682861328, 1.083543300628662, 1.0890672206878662, 1.1307851076126099, 1.144077181816101, 1.0661863088607788, 1.0618385076522827, 1.0697872638702393, 1.0747019052505493, 1.0927379131317139, 1.0669149160385132, 1.0670559406280518, 1.0811518430709839, 1.0941718816757202, 1.0692944526672363, 1.2958506345748901, 1.0779802799224854, 1.0714962482452393, 1.0801535844802856, 1.0625104904174805, 1.0848126411437988, 1.1094597578048706, 1.0996564626693726, 1.0532201528549194, 1.055601716041565, 1.0678505897521973, 1.0560849905014038, 1.0646690130233765, 1.0759379863739014, 1.1025311946868896, 1.0822252035140991, 1.0649913549423218, 1.0550825595855713, 1.061888337135315, 1.0964986085891724, 1.0707472562789917, 1.0537519454956055, 1.0964254140853882, 1.052740216255188, 1.0488630533218384, 1.062792420387268, 1.0967752933502197, 1.054039478302002, 1.066369891166687, 1.046127200126648, 1.0480023622512817, 1.062334656715393, 1.046217441558838, 1.0692024230957031, 1.0876222848892212, 1.0423473119735718, 1.2330633401870728, 1.0426974296569824, 1.0502973794937134, 1.0723270177841187, 1.0443780422210693, 1.0459173917770386, 1.0506402254104614, 1.045325517654419, 1.0463109016418457, 1.0962449312210083, 1.0480910539627075, 1.0435246229171753, 1.0372862815856934, 1.1659678220748901, 1.0407003164291382, 1.0946922302246094, 1.1262701749801636, 1.0996482372283936, 1.0356132984161377, 1.0263426303863525, 1.046453595161438, 1.0498814582824707, 1.06220281124115, 1.3777426481246948, 1.0326436758041382, 1.081575632095337, 1.033740520477295, 1.0398777723312378, 1.046553134918213, 1.0603755712509155, 1.037874460220337, 1.1073461771011353, 1.0299808979034424, 1.030948281288147, 1.0203685760498047, 1.0650583505630493, 1.1267669200897217, 1.091055154800415, 1.0615897178649902, 1.0353381633758545, 1.0610065460205078, 1.0589300394058228, 1.049157738685608, 1.0436457395553589, 1.034045934677124, 1.040297508239746, 1.0646823644638062, 1.099960207939148, 1.0987271070480347, 1.3122496604919434, 1.0251665115356445, 1.0639910697937012, 1.0463248491287231, 1.0554207563400269, 1.0694595575332642, 1.014280915260315, 1.0899388790130615, 1.0156370401382446, 1.0651092529296875, 1.0187746286392212, 1.020513653755188, 1.0388025045394897, 1.033181071281433, 1.1729182004928589, 1.0543140172958374, 1.0875047445297241, 1.0356327295303345, 1.0208314657211304, 1.0651161670684814, 1.0215660333633423, 1.0548046827316284, 1.00828218460083, 1.019240379333496, 1.0296454429626465, 1.1122267246246338, 1.0362476110458374, 1.0181636810302734, 1.0352115631103516, 1.020021677017212, 1.0317379236221313, 1.0010216236114502, 1.0012686252593994, 1.0101326704025269, 1.0547475814819336, 1.0021731853485107, 1.013350009918213, 1.0120173692703247, 1.0581538677215576, 1.0158153772354126, 1.0992028713226318, 1.008378267288208, 1.0477603673934937, 1.0202618837356567, 0.995500385761261, 1.0937473773956299, 0.9931606650352478, 1.0581449270248413, 1.0654220581054688, 1.0168732404708862, 1.0145734548568726, 1.0119867324829102, 1.0143191814422607, 0.9950541853904724, 1.0261051654815674, 1.0092869997024536, 0.9926398396492004, 1.0612890720367432, 0.9949285387992859, 1.0132108926773071, 0.9938215017318726, 1.0114086866378784, 1.2701009511947632]\n",
      "0.986035943031311\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    student = DeepAntiNet(n, d, hidden_dim, anti_dim)\n",
    "    losses = train(student, train_x, train_y, iterations, lr = 0.0025)\n",
    "    print(losses[::50])\n",
    "    print(min(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5587cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75.35175323486328, 26.88316535949707, 10.985112190246582, 6.651232719421387, 5.025967121124268, 4.157585144042969, 3.60455584526062, 3.2522475719451904, 3.007519245147705, 2.7913570404052734, 2.617907762527466, 2.477581262588501, 2.371523141860962, 2.2269725799560547, 2.1166398525238037, 2.045684814453125, 1.938610315322876, 1.8895525932312012, 1.8510980606079102, 1.7752336263656616, 1.7310562133789062, 1.6829882860183716, 1.703217625617981, 1.6123077869415283, 1.5615037679672241, 1.5194311141967773, 1.4945552349090576, 1.484784722328186, 1.433695673942566, 1.4250519275665283, 1.4044640064239502, 1.3823468685150146, 1.358427882194519, 1.3484439849853516, 1.3306024074554443, 1.3096555471420288, 1.3183000087738037, 1.292242169380188, 1.278598427772522, 1.3161906003952026, 1.2624006271362305, 1.2468044757843018, 1.2346489429473877, 1.2465819120407104, 1.2361586093902588, 1.2222607135772705, 1.2185897827148438, 1.1802247762680054, 1.1862661838531494, 1.1698143482208252, 1.1598702669143677, 1.2060822248458862, 1.1451878547668457, 1.1348392963409424, 1.1353631019592285, 1.1503400802612305, 1.128326654434204, 1.10044264793396, 1.0986515283584595, 1.0952205657958984, 1.0784872770309448, 1.0790247917175293, 1.0983026027679443, 1.0658702850341797, 1.0740755796432495, 1.0557754039764404, 1.05889892578125, 1.0729405879974365, 1.043164849281311, 1.0495191812515259, 1.0547372102737427, 1.0249544382095337, 1.0177478790283203, 1.0240334272384644, 1.0148816108703613, 1.0138381719589233, 1.0041241645812988, 1.0358481407165527, 1.013866901397705, 0.9980323314666748, 0.9966788291931152, 0.9853182435035706, 0.9752562642097473, 0.9791990518569946, 1.0208699703216553, 0.9683733582496643, 0.9686002135276794, 1.0366498231887817, 0.9608781933784485, 0.9610837697982788, 0.981909990310669, 0.9563282132148743, 0.9429616928100586, 0.9441233277320862, 0.9406409859657288, 0.9430537223815918, 0.9327724575996399, 0.9564458727836609, 1.00007963180542, 0.9337983131408691, 0.9248712062835693, 0.916681170463562, 0.9186099767684937, 0.9123461842536926, 0.9129071235656738, 0.9107484221458435, 0.9165449142456055, 0.8976054787635803, 0.8954054713249207, 0.8952743411064148, 0.9213466048240662, 0.9164636731147766, 0.8862001895904541, 0.8864496350288391, 0.8926403522491455, 0.8788129687309265, 0.8705465793609619, 0.8725541234016418, 0.8703972697257996, 0.868628203868866, 0.8720236420631409, 0.9212474822998047, 0.8908036947250366, 0.8520316481590271, 0.8550901412963867, 0.8501450419425964, 0.8534753918647766, 0.8414040803909302, 0.8364782333374023, 0.8449729681015015, 0.8594179749488831, 0.8620925545692444, 0.8535676002502441, 0.8258578181266785, 0.8337911367416382, 0.8344401121139526, 0.8215503096580505, 0.8389334678649902, 0.8234360218048096, 0.8199598789215088, 0.8217998743057251, 0.8152838945388794, 0.8167428970336914, 0.8147268891334534, 0.8153177499771118, 0.8097873330116272, 0.8010555505752563, 0.8043533563613892, 0.8287319540977478, 0.8422034978866577, 0.8105553984642029, 0.8156903386116028, 0.7978125214576721, 0.791731059551239, 0.79424649477005, 0.7901970148086548, 0.7860393524169922, 0.7858409881591797, 0.7899618744850159, 0.7886161804199219, 0.7894771695137024, 0.7941934466362, 0.7750604748725891, 0.8399974703788757, 0.9120787978172302, 0.7707997560501099, 0.7663933634757996, 0.7750198245048523, 0.7758080363273621, 0.7639597058296204, 0.769308865070343, 0.778418242931366, 0.7806004881858826, 0.7888269424438477, 0.8086008429527283, 0.7491029500961304, 0.7549523711204529, 0.751743495464325, 0.7466326951980591, 0.7419169545173645, 0.7405585646629333, 0.7449015974998474, 0.7581320405006409, 0.7454871535301208, 0.7335889935493469, 0.7352612018585205, 0.7320660948753357, 0.7422215938568115, 0.7851020693778992, 0.7827821373939514, 0.7402850389480591, 0.7220312356948853, 0.7210160493850708, 0.720587968826294, 0.7251549363136292, 0.7416579127311707, 0.7245165109634399, 0.7183594107627869, 0.7783055901527405, 0.7451167702674866, 0.7357688546180725, 0.7247517108917236, 0.7058887481689453, 0.7219327688217163, 0.7241010665893555, 0.7190868258476257, 0.7168617248535156, 0.7136505246162415, 0.7009671330451965, 0.7037433385848999, 0.7872393727302551, 0.7140961289405823, 0.6934047341346741, 0.699410617351532, 0.6939336061477661, 0.7000700831413269, 0.7105406522750854, 0.7044305801391602, 0.6988000869750977, 0.6896392107009888, 0.7215417623519897, 0.685390293598175, 0.719779908657074, 0.6973832845687866, 0.6857399940490723, 0.681721568107605, 0.6929522752761841, 0.6813293695449829, 0.6876065135002136, 0.6825730800628662, 0.6820428967475891, 0.6886906027793884, 0.6734226942062378, 0.6749024987220764, 0.6952807307243347, 0.6743739247322083, 0.6754758954048157, 0.6784733533859253, 0.7163823246955872, 0.6707500219345093, 0.6771140098571777, 0.672109842300415, 0.6688665747642517, 0.6797935366630554, 0.702743649482727, 0.6766620874404907, 0.6615470051765442, 0.6711446046829224, 0.6962096691131592, 0.670779287815094, 0.6604681015014648, 0.6787126064300537, 0.6896113157272339, 0.7456730604171753, 0.669751763343811, 0.6634476184844971, 0.6759690642356873, 0.7203547358512878, 0.6541607975959778, 0.6641867756843567, 0.6559743285179138, 0.6895925402641296, 0.7250418066978455, 0.6886094808578491, 0.6504610180854797, 0.6742347478866577, 0.6455487012863159, 0.649174153804779, 0.6628896594047546, 0.6926030516624451, 0.6724417805671692, 0.7282706499099731, 0.642971932888031, 0.6407905220985413, 0.6519412398338318, 0.6507149338722229, 0.6475474834442139, 0.6537296175956726, 0.6358770132064819, 0.649490475654602, 0.6435549855232239, 0.6426350474357605, 0.6549240946769714, 0.6559537649154663, 0.6376366019248962, 0.6429787278175354, 0.6365088224411011, 0.6415960192680359, 0.6354088187217712, 0.6513234972953796, 0.6365051865577698, 0.7438151240348816, 0.6383556127548218, 0.6356760263442993, 0.6276106834411621, 0.6412578821182251, 0.6462028622627258, 0.7345819473266602, 0.6524226069450378, 0.6256698966026306, 0.6295057535171509, 0.6250272989273071, 0.6321897506713867, 0.6259157657623291, 0.6259440183639526, 0.6335657238960266, 0.6235101819038391, 0.6236229538917542, 0.6286146640777588, 0.6293115019798279, 0.7076894640922546, 0.6294618844985962, 0.6218230724334717, 0.6310763955116272, 0.6604434251785278, 0.6334730982780457, 0.6312338709831238, 0.629463255405426, 0.6205988526344299, 0.6344163417816162, 0.6371167898178101, 0.6193015575408936, 0.6212324500083923, 0.6149502992630005, 0.6300248503684998, 0.618722677230835, 0.6177605390548706, 0.619915783405304, 0.6702629327774048, 0.6192266941070557, 0.6178166270256042, 0.625279426574707, 0.6683401465415955, 0.6132633090019226, 0.6575585007667542, 0.6422001719474792, 0.6239633560180664, 0.6207011938095093, 0.6213797926902771, 0.6146830320358276, 0.6082314252853394, 0.6610864400863647, 0.6143789291381836, 0.6092847585678101, 0.6290740370750427, 0.6391493082046509, 0.6360982060432434, 0.6234393119812012, 0.6076464056968689, 0.6085564494132996, 0.6222104430198669, 0.6213704347610474, 0.6038746237754822, 0.6043106913566589, 0.6010023355484009, 0.6420185565948486, 0.6126654744148254, 0.6074914336204529, 0.6075626611709595, 0.6032436490058899, 0.6070739030838013, 0.600399911403656, 0.6300884485244751, 0.6084273457527161, 0.6122084856033325, 0.6057375073432922, 0.6303097605705261, 0.6220680475234985, 0.5985568165779114, 0.6023280620574951, 0.6041087508201599, 0.9055582284927368, 0.6551270484924316, 0.6448974609375, 0.6834782361984253, 0.6516590714454651, 0.7039828896522522, 0.6553486585617065, 0.661842405796051, 0.6228390336036682, 0.6345586180686951, 0.6233000755310059, 0.6255983114242554, 0.6016662120819092, 0.6088966131210327, 0.6039031147956848, 0.6156906485557556, 0.6249005794525146, 0.5986958742141724, 0.6027887463569641, 0.6111286878585815, 0.6080774664878845, 0.6519321799278259, 0.5984817147254944, 0.6000386476516724, 0.6135804653167725, 0.6093618869781494, 0.5996717214584351, 0.6012773513793945, 0.6081706285476685]\n",
      "0.588127613067627\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    student = MultiBackflow(n, d, hidden_dim, anti_dim)\n",
    "    losses = train(student, train_x, train_y, iterations, lr = 0.0025)\n",
    "    print(losses[::50])\n",
    "    print(min(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50781214",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    student = DeepMultiBackflow(n, d, hidden_dim, anti_dim)\n",
    "    losses = train(student, train_x, train_y, iterations, lr = 0.0025)\n",
    "    print(losses[::50])\n",
    "    print(min(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c0f15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([6.588473796844482, 6.398560047149658, 7.056000232696533])\n",
    "b = np.array([6.899078845977783, 5.879907608032227, 5.7301530838012695])\n",
    "c = np.array([4.987086296081543, 4.876344203948975, 4.408130645751953])\n",
    "\n",
    "x_pos = np.arange(3)\n",
    "names = [\"Default\", \"One Extra Layer\", \"Two Extra Layers\"]\n",
    "means = [np.mean(a), np.mean(b), np.mean(c)]\n",
    "stds = [np.std(a), np.std(b), np.std(c)]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x_pos, means, yerr=stds, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "ax.set_ylabel('Mean Squared Error')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(names)\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "# Save the figure and show\n",
    "plt.tight_layout()\n",
    "plt.savefig('bar_plot_with_error_bars.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6d291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prime] *",
   "language": "python",
   "name": "conda-env-prime-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
